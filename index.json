[{"authors":["xueqin-wang"],"categories":null,"content":"Xueqin Wang is a professor of Statistics at the Department of Statistics and Finance, School of Management, University of Science and Technology of China (USTC). He received his bachelor’s degree in mathematics from Nankai University and a Ph.D. degree in statistics from Binghamton University in 1997 and 2003. Before joining USTC in March 2020, He worked as a professor at Sun Yat-sen University, received postdoctoral training at Yale School of Public Health, and worked as a visiting assistant professor at the University of Mississippi. He was selected into the New Century Excellent Talent Program of the Ministry of Education of China in 2012 and won the Excellent Young Scholar Award in 2013. He has been a member of the Steering Committee for Statistics Education, Ministry of Education since 2013. He serves as an associate editor of the Journal of the American Statistical Association - Applications and Case Studies, an associate editor of the Canadian Journal of Statistics, and an associate editor of Statistics and Its Interface. He also serves as an associate editor of Lecture Notes: Data Science, Statistics and Probability, Higher Education Press. He published over 80 research articles and monographs in theory and applications of statistical methods and several biomedical research areas, including epidemiology, genetics, and mental health. He released several open-source software packages such as Ball on the official website of R CRAN and Python PyPI with a total of 164,000 downloads. He is interested in Statistical theory and methods in statistical machine learning, biostatistics, social science with particular skills in high-dimensional statistics, non-Euclidean data analysis, Gaussian random field regression analysis, among other areas.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ef4bab643b3081cd77aed6d2f81471e2","permalink":"https://statlab905.github.io/author/xueqin-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xueqin-wang/","section":"authors","summary":"Xueqin Wang is a professor of Statistics at the Department of Statistics and Finance, School of Management, University of Science and Technology of China (USTC). He received his bachelor’s degree in mathematics from Nankai University and a Ph.","tags":null,"title":"Xueqin Wang","type":"authors"},{"authors":null,"categories":null,"content":"Abstract Our seminar consists two parts. In the first part, we cover selected topics in “Learning with Kernel”, including Loss functions, Regularization, Pattern Recognition, Implementation, Designing Kernels and Kernel Fisher Discriminant. In the second part, we report our research progress in topics of Nonparametric Statistics, including Tree methods, two sample tests on Hyperbolic Space and Change Point Detection.\nTime and Location Time: 7:00pm-9:00pm, Tuesday, 2022 Spring\nLocation: USTC Management Science Building 1008 and Online\n","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"ffd83ebe679b1338a8239cfbb09e41d3","permalink":"https://statlab905.github.io/seminar/nonparametric/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/seminar/nonparametric/","section":"seminar","summary":"We cover selected topics in Kernel Learning and research progress in Nonparametric Statistics.","tags":null,"title":"Seminar on Nonparametric Statistics","type":"seminar"},{"authors":null,"categories":null,"content":"Abstract We cover selected topics in “Numerical Optimization”, including Line Search Method, Trust Region Method, Conjugate Gradient Method, Quasi-Newton Methods and Simplex Optimization. Besides, in the middle of the term, we listen Prof Bingsheng He from Nanjing University presenting his work on Optimization.\nTime and Location Time: 7:00pm-9:00pm, Tuesday, 2022 Spring\nLocation: USTC Management Science Building 1008 and Online\nLearning Materials Materials are continuously updated on our Github repository.\n","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"f033416f1affaa507a99ff889abf643f","permalink":"https://statlab905.github.io/seminar/optimization/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/seminar/optimization/","section":"seminar","summary":"We present the basic tools in Optimization and listen the lectures presented by Prof. Bingsheng He.","tags":null,"title":"Seminar on Optimization and Algorithm","type":"seminar"},{"authors":null,"categories":null,"content":"Abstract Our seminar mainly focuses on the book “Reinforcement Learning :An Introduction”. We the basic parts of Reinforcement Learning, including Multi Armed Bandit, Thompson Sampling, Markov Decision Process, Monte Carlo Methods, Temporal-Difference Learning, On-policy Approximations and Policy Gradient Methods. We not only present the Theory of the methods in our seminar, but also use some experiment to illustrate our method.\nTime 9:30am-11:30am, Tuesday, 2022 Spring\nMaterials Materials are continuously updated on our Github repository.\n","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656633600,"objectID":"92486b974205f79036b50920562d688d","permalink":"https://statlab905.github.io/seminar/rl/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/seminar/rl/","section":"seminar","summary":"We cover selected topics Reinforcement Learning.","tags":null,"title":"Seminar on Reinforcement Learning","type":"seminar"},{"authors":[],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"e56e4d397f4c1b9fa110760a006f3570","permalink":"https://statlab905.github.io/event/nonparametric/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/nonparametric/","section":"event","summary":"We cover selected topics in Kernel Learning and research progress in Nonparametric Statistics.","tags":[],"title":"Seminar on Nonparametric Statistics","type":"event"},{"authors":[],"categories":null,"content":"Materials are continuously updated on our Github repository.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"008738277b980b5e56e4c1ece92a8f12","permalink":"https://statlab905.github.io/event/optimization/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/optimization/","section":"event","summary":"We present the basic tools in Optimization and listen the lectures presented by Prof. Bingsheng He.","tags":[],"title":"Seminar on Optimization and Algorithm","type":"event"},{"authors":[],"categories":null,"content":"Time 9:30am-11:30am, Tuesday, 2022 Spring\nMaterials Materials are continuously updated on our Github repository.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f39542af8b751a58f43b9736ebd3ae4a","permalink":"https://statlab905.github.io/event/rl/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/rl/","section":"event","summary":"We cover selected topics Reinforcement Learning.","tags":[],"title":"Seminar on Reinforcement Learning","type":"event"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://statlab905.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://statlab905.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"\rOverview abess (Adaptive BEst Subset Selection) library aims to solve general best subset selection, i.e., find a small subset of predictors such that the resulting model is expected to have the highest accuracy. The selection for best subset shows great value in scientific researches and practical applications. For example, clinicians want to know whether a patient is healthy or not based on the expression levels of a few of important genes.\nThis library implements a generic algorithm framework to find the optimal solution in an extremely fast way. This framework now supports the detection of best subset under: linear regression, classification (binary or multi-class), counting-response modeling, censored-response modeling, multi-response modeling (multi-tasks learning), etc. It also supports the variants of best subset selection like group best subset selection, nuisance penalized regression, Especially, the time complexity of (group) best subset selection for linear regression is certifiably polynomial.\nQuick start The abess software has both Python and R’s interfaces. Here a quick start will be given and for more details, please view: Installation.\nPython package Install the stable version of Python-package from Pypi:\n$ pip install abess or conda-forge:\n$ conda install abess Best subset selection for linear regression on a simulated dataset in Python:\nfrom abess.linear import LinearRegression from abess.datasets import make_glm_data sim_dat = make_glm_data(n = 300, p = 1000, k = 10, family = \u0026#34;gaussian\u0026#34;) model = LinearRegression() model.fit(sim_dat.x, sim_dat.y) See more examples analyzed with Python in the Python tutorials.\nR package Install the stable version of R-package from CRAN with:\ninstall.packages(\u0026#34;abess\u0026#34;) Best subset selection for linear regression on a simulated dataset in R:\nlibrary(abess) sim_dat \u0026lt;- generate.data(n = 300, p = 1000) abess(x = sim_dat[[\u0026#34;x\u0026#34;]], y = sim_dat[[\u0026#34;y\u0026#34;]]) See more examples analyzed with R in the R tutorials.\nRuntime Performance To show the power of abess in computation, we assess its timings of the CPU execution (seconds) on synthetic datasets, and compare to state-of-the-art variable selection methods. The variable selection and estimation results are deferred to Python performance and R performance. All computations are conducted on a Ubuntu platform with Intel(R) Core(TM) i9-9940X CPU @ 3.30GHz and 48 RAM.\nPython package We compare abess Python package with scikit-learn on linear regression and logistic regression. Results are presented in the below figure:\nIt can be see that abess uses the least runtime to find the solution.\nR package We compare abess R package with three widely used R packages: glmnet, ncvreg, and L0Learn. We get the runtime comparison results:\nCompared with other packages, abess shows competitive computational efficiency, and achieves the best computational power when variables have a large correlation.\nOpen source software abess is a free software and its source code is publicly available on Github. The core framework is programmed in C++, and user-friendly R and Python interfaces are offered. You can redistribute it and/or modify it under the terms of the GPL-v3 License. We welcome contributions for abess, especially stretching abess to the other best subset selection problems.\nWhat’s news New features:\nabess Python package can be installed via conda. abess R package is is highlighted as one of the core packages in CRAN Task View: Machine Learning \u0026amp; Statistical Learning. On Windows, the recommended C++ compiler shifts from Mingw to Microsoft Visual Studio. Support predicting survival function in abess.linear.CoxPHSurvivalAnalysis. Rename estimators in Python. Please check here. New best subset selection tasks:\nGeneralized linear model for ordinal regression (a.k.a rank learning in some machine learning literature). Citation If you use abess or reference our tutorials in a presentation or publication, we would appreciate citations of our library.\nJin Zhu, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Shiyun Lin, Junxian Zhu (2022). “abess: A Fast Best Subset Selection Library in Python and R.” Journal of Machine Learning Research (Accepted).\nThe corresponding BibteX entry:\n@article{zhu2022abess,\rauthor = {Jin Zhu and Xueqin Wang and Liyuan Hu and Junhao Huang and Kangkang Jiang and Yanhang Zhang and Shiyun Lin and Junxian Zhu},\rtitle = {abess: A Fast Best Subset Selection Library in Python and R},\rjournal = {Journal of Machine Learning Research (Accepted)},\ryear = {2022}\r} References Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, and Xueqin Wang (2020). A polynomial algorithm for best-subset selection problem. Proceedings of the National Academy of Sciences, 117(52):33117-33123. Pölsterl, S (2020). scikit-survival: A Library for Time-to-Event Analysis Built on Top of scikit-learn. J. Mach. Learn. Res., 21(212), 1-6. Yanhang Zhang, Junxian Zhu, Jin Zhu, and Xueqin Wang (2021). Certifiably Polynomial Algorithm for Best …","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1bf558e8a0c78335c920373911cf08bc","permalink":"https://statlab905.github.io/softwares/abess/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/softwares/abess/","section":"softwares","summary":"abess implements a unified framework of best-subset selection for solving diverse machine learning problems, e.g., linear regression, classification, and principal component analysis. Particularly, abess certifiably gets the optimal solution within polynomial time with high probability under the linear model. Our efficient implementation allows abess to attain the solution of best-subset selection problems as fast as or even 20-times faster than existing competing variable (model) selection toolboxes. Furthermore, it supports common variants like best subset of groups selection and ridge-regularized best-subset selection. The core of the library is programmed in C++. For ease of use, a Python library is designed for convenient integration with sklearn, and it can be installed from the Python Package Index (PyPI). In addition, a user-friendly R library is available at the Comprehensive R Archive Network (CRAN). The full [documentation](https://abess.readthedocs.io/) is online accessible.","tags":["variable selection","high-dimensional data","linear regression","logistic regression","poisson regression","gamma regression","multi-task learning","multi-classification","rank learning","group variable selection","principal component analysis","robust principal component analysis"],"title":"abess -- A Fast Best-Subset Selection Library in Python and R","type":"softwares"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://statlab905.github.io/tour/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"widget_page"}]